from flask import Flask, request, jsonify
from flask_cors import CORS
from PIL import Image
import io
import torch
from torchvision import transforms, models
import traceback
import os

app = Flask(__name__)
CORS(app)  # ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï cross-origin requests
app.config['MAX_CONTENT_LENGTH'] = 5 * 1024 * 1024  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå 5MB

# ===============================
# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• PyTorch ‡πÅ‡∏ö‡∏ö checkpoint
# ===============================
def load_leaf_model(path="leaf_model.pt"):
    """‡πÇ‡∏´‡∏•‡∏î MobileNetV3 (Leaf/Not Leaf) ‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏õ‡πÑ‡∏õ‡∏ó‡∏µ‡πà CPU"""
    full_path = os.path.join(os.getcwd(), path)
    
    try:
        # **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÉ‡∏ä‡πâ map_location="cpu" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ GPU
        checkpoint = torch.load(full_path, map_location="cpu")
        state_dict = checkpoint.get("model", checkpoint) # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ key 'model' ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ

        model = models.mobilenet_v3_small(weights=None) # weights=None ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏à‡∏≤‡∏Å state_dict
        model.classifier[-1] = torch.nn.Linear(1024, 2) # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö MobileNetV3 small ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Input features ‡∏Ç‡∏≠‡∏á Classifier ‡∏ä‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢)
        
        # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö MobileNetV3_small output feature ‡∏Ç‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏ä‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠ 1024
        # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∏‡∏ì‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏á ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏•‡∏Ç 1024
        
        # Note: ‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°‡∏Ñ‡∏∑‡∏≠ model.classifier[3] = torch.nn.Linear(576, 2) ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö mobilenet_v3_small
        # ‡∏ú‡∏°‡πÅ‡∏Å‡πâ‡πÄ‡∏õ‡πá‡∏ô model.classifier[-1] = torch.nn.Linear(1024, 2) 

        model.load_state_dict(state_dict)
        model.eval()
        print(f"‚úÖ Leaf model loaded from {full_path}")
        return model
    except Exception as e:
        print(f"‚ùå Failed to load leaf model from {full_path}:", e)
        # ‡∏´‡∏≤‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô ‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö) ‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏°‡∏û‡πå stack trace
        traceback.print_exc()
        return None

def load_type_model(path="type_model.pt"):
    """‡πÇ‡∏´‡∏•‡∏î EfficientNetV2 (Type Classification) ‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏õ‡πÑ‡∏õ‡∏ó‡∏µ‡πà CPU"""
    full_path = os.path.join(os.getcwd(), path)
    
    try:
        # **‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç:** ‡πÉ‡∏ä‡πâ map_location="cpu"
        checkpoint = torch.load(full_path, map_location="cpu")
        state_dict = checkpoint.get("model", checkpoint) # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ key 'model' ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ

        model = models.efficientnet_v2_s(weights=None)
        # EfficientNetV2-S ‡∏°‡∏µ 1280 features ‡∏Å‡πà‡∏≠‡∏ô Classifier ‡∏ä‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        model.classifier[1] = torch.nn.Linear(1280, 4)  # 4 classes: basil, spinach, mint, unknown

        model.load_state_dict(state_dict)
        model.eval()
        print(f"‚úÖ Type model loaded from {full_path}")
        return model
    except Exception as e:
        print(f"‚ùå Failed to load type model from {full_path}:", e)
        traceback.print_exc()
        return None

# ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà Working Directory ‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô Gunicorn
leaf_model = load_leaf_model()
type_model = load_type_model()

if leaf_model is None or type_model is None:
    # Raise error ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Gunicorn/Docker ‡∏ó‡∏£‡∏≤‡∏ö‡∏ß‡πà‡∏≤ initialization ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß
    raise RuntimeError("One or both PyTorch models failed to load. Check model files (leaf_model.pt/type_model.pt) and paths.")

# ===============================
# Preprocess ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PyTorch ‡πÇ‡∏°‡πÄ‡∏î‡∏•
# ===============================
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
])

# ===============================
# Flask route /predict
# ===============================
@app.route("/predict", methods=["POST"])
def predict():
    if leaf_model is None or type_model is None:
        return jsonify({
            "error": "Model Initialization Error",
            "details": "One or both PyTorch models failed to load during startup."
        }), 500

    try:
        if "image" not in request.files:
            return jsonify({"error": "Missing 'image' in request.files"}), 400

        file = request.files["image"]
        img_bytes = file.read()
        # ‡πÉ‡∏ä‡πâ Image.open(io.BytesIO(...)) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ PIL ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
        img = Image.open(io.BytesIO(img_bytes)).convert("RGB")
        print(f"‚úÖ Received image: {file.filename}, size: {img.size}")

        # ===============================
        # ‡πÇ‡∏°‡πÄ‡∏î‡∏• 1: ‡∏ï‡∏£‡∏ß‡∏à‡πÉ‡∏ö/‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡πÉ‡∏ö
        # ===============================
        leaf_tensor = preprocess(img).unsqueeze(0)
        with torch.no_grad():
            leaf_out = leaf_model(leaf_tensor)
            leaf_probs = torch.nn.functional.softmax(leaf_out, dim=1)
            leaf_conf, leaf_pred = torch.max(leaf_probs, dim=1)
            # 1 ‡∏Ñ‡∏∑‡∏≠ "leaf", 0 ‡∏Ñ‡∏∑‡∏≠ "not_leaf" (‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö class)
            is_leaf = bool(leaf_pred.item() == 1) 

        leaf_predictions = {
            "class": "leaf" if is_leaf else "not_leaf",
            "confidence": float(leaf_conf.item())
        }

        if not is_leaf:
            return jsonify({
                "leafCheck": "no",
                "leafPredictions": leaf_predictions,
                "message": "This image is not classified as a leaf.",
                "filename": file.filename,
                "image_size": img.size
            })

        # ===============================
        # ‡πÇ‡∏°‡πÄ‡∏î‡∏• 2: ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏ö
        # ===============================
        type_tensor = preprocess(img).unsqueeze(0)
        with torch.no_grad():
            type_out = type_model(type_tensor)
            type_probs = torch.nn.functional.softmax(type_out, dim=1)
            type_conf, type_pred = torch.max(type_probs, dim=1)

        type_classes = ["basil", "spinach", "mint", "unknown"]
        best_class = type_classes[type_pred.item()] 
        best_conf = float(type_conf.item())

        print(f"üü¢ Leaf detected ‚Üí type: {best_class} (Conf: {best_conf:.4f})")

        return jsonify({
            "leafCheck": "yes",
            "leafPredictions": leaf_predictions,
            "bestPrediction": {
                "class": best_class,
                "confidence": best_conf
            },
            "filename": file.filename,
            "image_size": img.size
        })

    except Exception as e:
        detailed_error = traceback.format_exc()
        print("‚ùå ERROR DURING PREDICTION")
        print(detailed_error)
        return jsonify({
            "error": "Prediction failed due to internal error",
            "details": str(e)
        }), 500

# ===============================
# Health check (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Deployment)
# ===============================
@app.route("/health")
def health():
    if leaf_model and type_model:
        return {"status": "ok", "message": "All models loaded successfully."}, 200
    return {"status": "model load failed", "message": "One or more PyTorch models are not initialized."}, 500

if __name__ == "__main__":
    # ‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Flask's development server 
    app.run(host="0.0.0.0", port=5000, debug=True)
